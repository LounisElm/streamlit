{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91eb2a9c",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "This notebook evaluates the performance of different feature and regressor combinations on both MovieLens and Hackathon datasets.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import accuracy\n",
    "from models import ContentBased\n",
    "from loaders import load_ratings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7b547",
   "metadata": {},
   "source": [
    "## 1. Define Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af266a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(features_method, regressor_method, dataset='normal'):\n",
    "    \"\"\"\n",
    "    Evaluate a model with specific feature and regressor methods\n",
    "\n",
    "    Args:\n",
    "        features_method (str): Method to extract features\n",
    "        regressor_method (str): Regressor to use\n",
    "        dataset (str): 'normal' or 'hackathon'\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing RMSE, MAE, and training time\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    df_ratings = load_ratings()\n",
    "\n",
    "    # Create and train model\n",
    "    start_time = time.time()\n",
    "    model = ContentBased(features_method=features_method, regressor_method=regressor_method)\n",
    "    model.fit(df_ratings)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(df_ratings)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(np.mean((df_ratings['rating'] - predictions) ** 2))\n",
    "    mae = np.mean(np.abs(df_ratings['rating'] - predictions))\n",
    "\n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'Time': training_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025b82d",
   "metadata": {},
   "source": [
    "## 2. Evaluate Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a57b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combinations to test\n",
    "normal_combinations = [\n",
    "    ('all_features', 'linear_regression'),\n",
    "    ('all_features', 'random_forest'),\n",
    "    ('all_features', 'xgboost'),\n",
    "    ('all_features', 'neural_network')\n",
    "]\n",
    "\n",
    "# Evaluate each combination\n",
    "normal_results = {}\n",
    "for features, regressor in normal_combinations:\n",
    "    print(f\"Evaluating {features} with {regressor}...\")\n",
    "    results = evaluate_model(features, regressor, 'normal')\n",
    "    normal_results[f\"{features}_{regressor}\"] = results\n",
    "\n",
    "# Create DataFrame\n",
    "normal_df = pd.DataFrame(normal_results).T\n",
    "display(normal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d1b30",
   "metadata": {},
   "source": [
    "## 3. Evaluate Hackathon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ebbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combinations to test\n",
    "hackathon_combinations = [\n",
    "    ('genome_tags', 'linear_regression'),\n",
    "    ('all_features_with_genome', 'linear_regression'),\n",
    "    ('all_features_with_genome', 'random_forest'),\n",
    "    ('all_features_with_genome', 'xgboost'),\n",
    "    ('all_features_with_genome', 'neural_network')\n",
    "    # MÃ©thodes avec genome tags et features visuelles\n",
    "    (\"all_features_with_genome_and_visuals\", \"linear_regression\"),\n",
    "    (\"all_features_with_genome_and_visuals\", \"random_forest\"),\n",
    "    (\"all_features_with_genome_and_visuals\", \"xgboost\"),\n",
    "    (\"all_features_with_genome_and_visuals\", \"neural_network\")\n",
    "]\n",
    "\n",
    "# Evaluate each combination\n",
    "hackathon_results = {}\n",
    "for features, regressor in hackathon_combinations:\n",
    "    print(f\"Evaluating {features} with {regressor}...\")\n",
    "    results = evaluate_model(features, regressor, 'hackathon')\n",
    "    hackathon_results[f\"{features}_{regressor}\"] = results\n",
    "\n",
    "# Create DataFrame\n",
    "hackathon_df = pd.DataFrame(hackathon_results).T\n",
    "display(hackathon_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d93ac5",
   "metadata": {},
   "source": [
    "## 4. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40abedd6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Plot RMSE comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=normal_df.index, y='RMSE', data=normal_df)\n",
    "plt.title('Normal Dataset RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=hackathon_df.index, y='RMSE', data=hackathon_df)\n",
    "plt.title('Hackathon Dataset RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot training time comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=normal_df.index, y='Time', data=normal_df)\n",
    "plt.title('Normal Dataset Training Time')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=hackathon_df.index, y='Time', data=hackathon_df)\n",
    "plt.title('Hackathon Dataset Training Time')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBests combinaisons (RMSE):\")\n",
    "print(df_results.nsmallest(3, 'rmse'))\n",
    "\n",
    "print(\"\\nFastest:\")\n",
    "print(df_results.nsmallest(3, 'training_time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e47f8",
   "metadata": {},
   "source": [
    "## 5. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "results_dir = 'C:/Users/nicol/Documents/GitHub/Majeur-BA/RECOMMENDER-SYSTEM/mlsmm2156/evaluation/results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "normal_df.to_csv(os.path.join(results_dir, 'normal_results.csv'))\n",
    "hackathon_df.to_csv(os.path.join(results_dir, 'hackathon_results.csv'))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
